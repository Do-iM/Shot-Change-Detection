{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GenFunction\n",
    "import DataGenerator\n",
    "import FFmpegDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate N images per class ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataGenerator.generate(GenFunction.mix2image, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataGenerator.generate(GenFunction.mix4image, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataGenerator.generate(GenFunction.concat2image, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### decoding video ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.mp4 to DIR/XXXX.jpg\n",
    "FFmpegDecoder.video_to_image(\"sample.mp4\", \"sample_images\", 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIR1/XXXX.jpg and DIR1/YYYY.jpg to DIR2/XXXX.jpg\n",
    "DataGenerator.frame_to_input(GenFunction.concat4image, \"sample_images\", \"input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default setting\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AMD setting\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "os.environ[\"PLAIDML_EXPERIMENTAL\"] = \"1\"\n",
    "os.environ[\"PLAIDML_DEVICE_IDS\"] = \"opencl_amd_ellesmere.0\"\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import KerasFunction as K\n",
    "import VGGModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.keras = keras\n",
    "VGGModel.keras = keras\n",
    "K.gen_f = GenFunction.concat2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new model with random weights\n",
    "model = K.make_model()\n",
    "K.compile_model(model)\n",
    "\n",
    "# Train model\n",
    "K.train_model(model, train_steps = 400, valid_steps=100, epochs=2)\n",
    "\n",
    "# Save model\n",
    "K.save_model(\"model.h5\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new model with saved weights\n",
    "model = K.load_model(\"model.h5\")\n",
    "K.compile_model(model)\n",
    "\n",
    "# Check validation\n",
    "(_, data_gen) = K.get_data_gen(100)\n",
    "K.check_validation(model, data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make new model with saved weights\n",
    "model = K.load_model(\"model.h5\")\n",
    "K.compile_model(model)\n",
    "\n",
    "# detect from images\n",
    "K.detection(model, \"input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = K.load_model(\"model.h5\")\n",
    "K.compile_model(model)\n",
    "K.detection(model, \"valid/1_Cut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
